{
  "openapi": "3.0.3",
  "info": {
    "title": "LLM Tool Bridge API",
    "description": "An OpenAI-compatible proxy that adds tool/function calling capabilities to any LLM. This proxy intelligently manages multi-turn conversations, handles tool execution, and provides seamless integration with existing OpenAI SDK clients.",
    "version": "1.0.0",
    "contact": {
      "name": "LLM Tool Bridge Support"
    },
    "license": {
      "name": "MIT"
    }
  },
  "servers": [
    {
      "url": "http://localhost:3500",
      "description": "Main Proxy Server"
    },
    {
      "url": "http://localhost:3501",
      "description": "Admin API Server"
    }
  ],
  "tags": [
    {
      "name": "Chat",
      "description": "OpenAI-compatible chat completion endpoints with tool calling support"
    },
    {
      "name": "Models",
      "description": "Model discovery and management"
    },
    {
      "name": "Health",
      "description": "Service health and status endpoints"
    },
    {
      "name": "Admin",
      "description": "Administrative endpoints for managing LLM targets and configuration"
    }
  ],
  "paths": {
    "/v1/chat/completions": {
      "post": {
        "tags": ["Chat"],
        "summary": "Create chat completion",
        "description": "Creates a chat completion with support for tool/function calling. The proxy automatically handles tool execution across multiple rounds, managing the conversation flow between the LLM and tool responses. Compatible with OpenAI SDK.",
        "operationId": "createChatCompletion",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/ChatCompletionRequest"
              },
              "examples": {
                "simple": {
                  "summary": "Simple chat without tools",
                  "value": {
                    "model": "gpt-3.5-turbo",
                    "messages": [
                      {"role": "user", "content": "Hello, how are you?"}
                    ]
                  }
                },
                "withTools": {
                  "summary": "Chat with tool calling",
                  "value": {
                    "model": "gpt-3.5-turbo",
                    "messages": [
                      {"role": "user", "content": "What's the weather in San Francisco?"}
                    ],
                    "tools": [
                      {
                        "type": "function",
                        "function": {
                          "name": "get_weather",
                          "description": "Get the current weather",
                          "parameters": {
                            "type": "object",
                            "properties": {
                              "location": {"type": "string"}
                            },
                            "required": ["location"]
                          }
                        }
                      }
                    ]
                  }
                },
                "streaming": {
                  "summary": "Streaming response",
                  "value": {
                    "model": "gpt-3.5-turbo",
                    "messages": [
                      {"role": "user", "content": "Tell me a story"}
                    ],
                    "stream": true
                  }
                }
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ChatCompletionResponse"
                }
              },
              "text/event-stream": {
                "schema": {
                  "$ref": "#/components/schemas/ChatCompletionStreamResponse"
                }
              }
            }
          },
          "400": {
            "description": "Bad request - Invalid parameters",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          },
          "401": {
            "description": "Unauthorized - Invalid or missing API key",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          },
          "503": {
            "description": "Service unavailable - No LLM target configured",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          }
        },
        "security": [
          {"bearerAuth": []},
          {}
        ]
      }
    },
    "/v1/models": {
      "get": {
        "tags": ["Models"],
        "summary": "List available models",
        "description": "Returns a list of available models from the active LLM target. The proxy automatically fetches fresh model information from the backend and caches it for performance.",
        "operationId": "listModels",
        "responses": {
          "200": {
            "description": "List of available models",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ModelsResponse"
                },
                "example": {
                  "object": "list",
                  "data": [
                    {
                      "id": "gpt-3.5-turbo",
                      "object": "model",
                      "created": 1677649963,
                      "owned_by": "openai"
                    },
                    {
                      "id": "gpt-4",
                      "object": "model",
                      "created": 1687882411,
                      "owned_by": "openai"
                    }
                  ]
                }
              }
            }
          }
        }
      }
    },
    "/health": {
      "get": {
        "tags": ["Health"],
        "summary": "Check proxy health",
        "description": "Returns the health status of the proxy service, including the active LLM target information and admin port.",
        "operationId": "checkHealth",
        "responses": {
          "200": {
            "description": "Service is healthy",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HealthResponse"
                },
                "example": {
                  "status": "healthy",
                  "activeTarget": "OpenAI Production",
                  "adminPort": 3501
                }
              }
            }
          }
        }
      }
    },
    "/api/admin/targets": {
      "get": {
        "tags": ["Admin"],
        "summary": "List LLM targets",
        "description": "Returns all configured LLM targets. Each target represents a backend LLM service that the proxy can route requests to.",
        "operationId": "listTargets",
        "servers": [{"url": "http://localhost:3501"}],
        "responses": {
          "200": {
            "description": "List of configured targets",
            "content": {
              "application/json": {
                "schema": {
                  "type": "array",
                  "items": {
                    "$ref": "#/components/schemas/LLMTarget"
                  }
                }
              }
            }
          }
        }
      },
      "post": {
        "tags": ["Admin"],
        "summary": "Create LLM target",
        "description": "Creates a new LLM target configuration. The target will be available for routing immediately after creation.",
        "operationId": "createTarget",
        "servers": [{"url": "http://localhost:3501"}],
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/CreateTargetRequest"
              }
            }
          }
        },
        "responses": {
          "201": {
            "description": "Target created successfully",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/LLMTarget"
                }
              }
            }
          }
        }
      }
    },
    "/api/admin/targets/{targetId}": {
      "get": {
        "tags": ["Admin"],
        "summary": "Get target details",
        "description": "Returns detailed information about a specific LLM target.",
        "operationId": "getTarget",
        "servers": [{"url": "http://localhost:3501"}],
        "parameters": [
          {
            "name": "targetId",
            "in": "path",
            "required": true,
            "schema": {
              "type": "string"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "Target details",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/LLMTarget"
                }
              }
            }
          },
          "404": {
            "description": "Target not found"
          }
        }
      },
      "put": {
        "tags": ["Admin"],
        "summary": "Update target",
        "description": "Updates an existing LLM target configuration.",
        "operationId": "updateTarget",
        "servers": [{"url": "http://localhost:3501"}],
        "parameters": [
          {
            "name": "targetId",
            "in": "path",
            "required": true,
            "schema": {
              "type": "string"
            }
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/UpdateTargetRequest"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Target updated successfully",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/LLMTarget"
                }
              }
            }
          }
        }
      },
      "delete": {
        "tags": ["Admin"],
        "summary": "Delete target",
        "description": "Removes an LLM target from the configuration.",
        "operationId": "deleteTarget",
        "servers": [{"url": "http://localhost:3501"}],
        "parameters": [
          {
            "name": "targetId",
            "in": "path",
            "required": true,
            "schema": {
              "type": "string"
            }
          }
        ],
        "responses": {
          "204": {
            "description": "Target deleted successfully"
          },
          "404": {
            "description": "Target not found"
          }
        }
      }
    },
    "/api/admin/models": {
      "get": {
        "tags": ["Admin"],
        "summary": "List cached models",
        "description": "Returns all models currently cached by the proxy from various LLM targets.",
        "operationId": "listCachedModels",
        "servers": [{"url": "http://localhost:3501"}],
        "responses": {
          "200": {
            "description": "List of cached models",
            "content": {
              "application/json": {
                "schema": {
                  "type": "array",
                  "items": {
                    "$ref": "#/components/schemas/Model"
                  }
                }
              }
            }
          }
        }
      }
    },
    "/api/admin/models/fetch/{targetId}": {
      "post": {
        "tags": ["Admin"],
        "summary": "Fetch models from target",
        "description": "Fetches available models from a specific LLM target and updates the cache.",
        "operationId": "fetchModelsFromTarget",
        "servers": [{"url": "http://localhost:3501"}],
        "parameters": [
          {
            "name": "targetId",
            "in": "path",
            "required": true,
            "schema": {
              "type": "string"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "Models fetched successfully",
            "content": {
              "application/json": {
                "schema": {
                  "type": "array",
                  "items": {
                    "$ref": "#/components/schemas/Model"
                  }
                }
              }
            }
          }
        }
      }
    },
    "/api/health": {
      "get": {
        "tags": ["Admin"],
        "summary": "Admin API health",
        "description": "Check the health status of the admin API.",
        "operationId": "checkAdminHealth",
        "servers": [{"url": "http://localhost:3501"}],
        "responses": {
          "200": {
            "description": "Admin API is healthy",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/AdminHealthResponse"
                }
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "ChatCompletionRequest": {
        "type": "object",
        "required": ["model", "messages"],
        "properties": {
          "model": {
            "type": "string",
            "description": "ID of the model to use"
          },
          "messages": {
            "type": "array",
            "description": "List of messages comprising the conversation",
            "items": {
              "$ref": "#/components/schemas/ChatMessage"
            }
          },
          "tools": {
            "type": "array",
            "description": "List of tools/functions available for the model to call",
            "items": {
              "$ref": "#/components/schemas/Tool"
            }
          },
          "tool_choice": {
            "oneOf": [
              {"type": "string"},
              {"type": "object"}
            ],
            "description": "Controls tool selection: 'auto', 'none', or specific tool"
          },
          "temperature": {
            "type": "number",
            "minimum": 0,
            "maximum": 2,
            "description": "Sampling temperature (0-2)"
          },
          "max_tokens": {
            "type": "integer",
            "description": "Maximum tokens to generate"
          },
          "stream": {
            "type": "boolean",
            "description": "Whether to stream the response"
          },
          "top_p": {
            "type": "number",
            "minimum": 0,
            "maximum": 1,
            "description": "Nucleus sampling parameter"
          },
          "frequency_penalty": {
            "type": "number",
            "minimum": -2,
            "maximum": 2,
            "description": "Frequency penalty"
          },
          "presence_penalty": {
            "type": "number",
            "minimum": -2,
            "maximum": 2,
            "description": "Presence penalty"
          }
        }
      },
      "ChatMessage": {
        "type": "object",
        "required": ["role", "content"],
        "properties": {
          "role": {
            "type": "string",
            "enum": ["system", "user", "assistant", "tool"],
            "description": "Message role"
          },
          "content": {
            "type": "string",
            "description": "Message content"
          },
          "name": {
            "type": "string",
            "description": "Name of the function (for tool messages)"
          },
          "tool_calls": {
            "type": "array",
            "description": "Tool calls made by the assistant",
            "items": {
              "$ref": "#/components/schemas/ToolCall"
            }
          },
          "tool_call_id": {
            "type": "string",
            "description": "ID of the tool call this message responds to"
          }
        }
      },
      "Tool": {
        "type": "object",
        "required": ["type", "function"],
        "properties": {
          "type": {
            "type": "string",
            "enum": ["function"],
            "description": "Tool type (currently only 'function' is supported)"
          },
          "function": {
            "$ref": "#/components/schemas/ToolFunction"
          }
        }
      },
      "ToolFunction": {
        "type": "object",
        "required": ["name", "description"],
        "properties": {
          "name": {
            "type": "string",
            "description": "Function name"
          },
          "description": {
            "type": "string",
            "description": "Function description for the model"
          },
          "parameters": {
            "type": "object",
            "description": "JSON Schema for function parameters"
          }
        }
      },
      "ToolCall": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "Unique identifier for this tool call"
          },
          "type": {
            "type": "string",
            "enum": ["function"]
          },
          "function": {
            "type": "object",
            "properties": {
              "name": {
                "type": "string",
                "description": "Name of the function to call"
              },
              "arguments": {
                "type": "string",
                "description": "JSON string of function arguments"
              }
            }
          }
        }
      },
      "ChatCompletionResponse": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "Unique identifier for the completion"
          },
          "object": {
            "type": "string",
            "enum": ["chat.completion"]
          },
          "created": {
            "type": "integer",
            "description": "Unix timestamp"
          },
          "model": {
            "type": "string",
            "description": "Model used"
          },
          "choices": {
            "type": "array",
            "items": {
              "$ref": "#/components/schemas/ChatChoice"
            }
          },
          "usage": {
            "$ref": "#/components/schemas/Usage"
          }
        }
      },
      "ChatChoice": {
        "type": "object",
        "properties": {
          "index": {
            "type": "integer",
            "description": "Choice index"
          },
          "message": {
            "$ref": "#/components/schemas/ChatMessage"
          },
          "finish_reason": {
            "type": "string",
            "enum": ["stop", "length", "tool_calls", "content_filter"],
            "description": "Reason for completion"
          }
        }
      },
      "Usage": {
        "type": "object",
        "properties": {
          "prompt_tokens": {
            "type": "integer",
            "description": "Tokens in the prompt"
          },
          "completion_tokens": {
            "type": "integer",
            "description": "Tokens in the completion"
          },
          "total_tokens": {
            "type": "integer",
            "description": "Total tokens used"
          }
        }
      },
      "ChatCompletionStreamResponse": {
        "type": "object",
        "description": "Server-sent event stream response",
        "properties": {
          "id": {
            "type": "string"
          },
          "object": {
            "type": "string",
            "enum": ["chat.completion.chunk"]
          },
          "created": {
            "type": "integer"
          },
          "model": {
            "type": "string"
          },
          "choices": {
            "type": "array",
            "items": {
              "$ref": "#/components/schemas/StreamChoice"
            }
          }
        }
      },
      "StreamChoice": {
        "type": "object",
        "properties": {
          "index": {
            "type": "integer"
          },
          "delta": {
            "$ref": "#/components/schemas/ChatMessage"
          },
          "finish_reason": {
            "type": "string"
          }
        }
      },
      "ModelsResponse": {
        "type": "object",
        "properties": {
          "object": {
            "type": "string",
            "enum": ["list"]
          },
          "data": {
            "type": "array",
            "items": {
              "$ref": "#/components/schemas/ModelInfo"
            }
          }
        }
      },
      "ModelInfo": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "Model identifier"
          },
          "object": {
            "type": "string",
            "enum": ["model"]
          },
          "created": {
            "type": "integer",
            "description": "Unix timestamp"
          },
          "owned_by": {
            "type": "string",
            "description": "Model provider"
          }
        }
      },
      "HealthResponse": {
        "type": "object",
        "properties": {
          "status": {
            "type": "string",
            "enum": ["healthy"],
            "description": "Service status"
          },
          "activeTarget": {
            "type": "string",
            "description": "Name of the active LLM target"
          },
          "adminPort": {
            "type": "integer",
            "description": "Admin API port number"
          }
        }
      },
      "AdminHealthResponse": {
        "type": "object",
        "properties": {
          "status": {
            "type": "string",
            "enum": ["ok"]
          },
          "activeTarget": {
            "type": "object",
            "properties": {
              "id": {"type": "string"},
              "name": {"type": "string"},
              "url": {"type": "string"}
            }
          },
          "timestamp": {
            "type": "string",
            "format": "date-time"
          }
        }
      },
      "LLMTarget": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "Unique identifier"
          },
          "name": {
            "type": "string",
            "description": "Display name"
          },
          "url": {
            "type": "string",
            "description": "Endpoint URL"
          },
          "model": {
            "type": "string",
            "description": "Default model to use"
          },
          "enabled": {
            "type": "boolean",
            "description": "Whether this target is enabled"
          },
          "priority": {
            "type": "integer",
            "description": "Priority for selection (lower is higher priority)"
          },
          "createdAt": {
            "type": "string",
            "format": "date-time"
          },
          "updatedAt": {
            "type": "string",
            "format": "date-time"
          }
        }
      },
      "CreateTargetRequest": {
        "type": "object",
        "required": ["name", "url", "model"],
        "properties": {
          "name": {
            "type": "string",
            "description": "Display name for the target"
          },
          "url": {
            "type": "string",
            "description": "Full URL to the chat completions endpoint"
          },
          "model": {
            "type": "string",
            "description": "Model identifier"
          },
          "apiKey": {
            "type": "string",
            "description": "API key for authentication (optional)"
          },
          "enabled": {
            "type": "boolean",
            "default": true
          },
          "priority": {
            "type": "integer",
            "default": 1
          }
        }
      },
      "UpdateTargetRequest": {
        "type": "object",
        "properties": {
          "name": {
            "type": "string"
          },
          "url": {
            "type": "string"
          },
          "model": {
            "type": "string"
          },
          "apiKey": {
            "type": "string"
          },
          "enabled": {
            "type": "boolean"
          },
          "priority": {
            "type": "integer"
          }
        }
      },
      "Model": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "Model identifier"
          },
          "name": {
            "type": "string",
            "description": "Model display name"
          },
          "provider": {
            "type": "string",
            "description": "Provider/target name"
          },
          "capabilities": {
            "$ref": "#/components/schemas/ModelCapabilities"
          }
        }
      },
      "ModelCapabilities": {
        "type": "object",
        "properties": {
          "streaming": {
            "type": "boolean",
            "description": "Supports streaming responses"
          },
          "functionCalling": {
            "type": "boolean",
            "description": "Supports function/tool calling"
          },
          "vision": {
            "type": "boolean",
            "description": "Supports image inputs"
          },
          "maxTokens": {
            "type": "integer",
            "description": "Maximum token limit"
          }
        }
      },
      "ErrorResponse": {
        "type": "object",
        "properties": {
          "error": {
            "type": "object",
            "properties": {
              "message": {
                "type": "string",
                "description": "Error message"
              },
              "type": {
                "type": "string",
                "description": "Error type"
              },
              "code": {
                "type": "string",
                "description": "Error code"
              }
            }
          }
        }
      }
    },
    "securitySchemes": {
      "bearerAuth": {
        "type": "http",
        "scheme": "bearer",
        "description": "Optional chat API key for secured endpoints"
      }
    }
  }
}